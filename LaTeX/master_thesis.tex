\documentclass[12pt, a4paper]{article}
\usepackage[left=3cm, right = 2cm, vmargin=2cm]{geometry}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[english]{babel}
\usepackage{setspace}
\usepackage{xcolor}
\usepackage{multicol}
\usepackage{float}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{titlesec}
\usepackage{bbm}
\usepackage[font=small,skip=2pt]{caption}
\usepackage[
backend=biber,
style=authoryear,
]{biblatex}
\usepackage{amsthm}% http://ctan.org/pkg/amsthm

\newtheoremstyle{MAstyle}
{\topsep} % Space above
{\topsep} % Space below
{} % Body font
{} % Indent amount
{\bfseries} % Theorem head font
{\newline} % Punctuation after theorem head
{.5em} % Space after theorem head
{} % Theorem head spec (can be left empty, meaning `normal')

\theoremstyle{MAstyle} \newtheorem{assumption}{Assumption}
\theoremstyle{MAstyle} \newtheorem{definition}{Definition}

\titleformat*{\section}{\Large\bfseries}
\titleformat*{\subsection}{\large\bfseries}

\addbibresource{thesis_bibliography.bib}
\onehalfspacing
\parindent=0pt

\begin{document}
	
	\title{{\huge Bugni and Horowitz (2021) Permutation Tests\\ for the Equality of Distributions of\\ Functional Data}}
	\date{}
	\maketitle
	\thispagestyle{empty}
	\vspace{1.5 cm}
	\begin{center}
		
		\Large
		Master's Thesis presented to the\\
		Department of Economics at the\\
		Rheinische Friedrich-Wilhelms-Universit√§t Bonn
		\vspace{1.5cm}

		\large
		In Partial Fulfillment of the Requirements for the Degree of\\
		Master of Science (M.Sc.)
		
		\vspace{3cm}
		
		Supervisor: Prof. Dr. Dominik Liebl
		
		\vspace{3cm}
		
		Submitted in June 2022 by: \\
		Jakob R. Juergens\\
		Matriculation Number: 2996491
	\end{center}
	
	\newpage
	
	\thispagestyle{empty}
	\tableofcontents
	
	\newpage
	\pagenumbering{arabic}
	
	\section{Introduction}
		In modern economics, it is becoming more and more common to use data measured at a very high frequency. As the frequency of observing a variable increases, it often becomes more natural to view the data not as a sequence of distinct observation points but as a smooth curve that describes the variable over time. \\
		This idea, to think of observations as measurements of a continuous process, is the motivating thought behind functional data analysis. Functional data analysis is a branch of statistics that has its beginnings in the 1940s and 1950s in the works of Ulf Grenander and Kari Karhunen. It gained traction during the following decades and focused more on possible applications during the 1990s. In Economics, functional data analysis is still a relatively exotic field, but it is beginning to become more established, which can be seen in the works of, for example, {\color{red} hier Autoren einfuegen}.
		
		A typical question in economics is whether observations from two or more data sets, e.g., data generated by treatment and control groups, are systematically different across groups. In statistical terms, this can be formulated as whether observations in both data sets can be seen as if the same stochastic process generated them.\\
		
		This question can also occur in functional data analysis, where each observation in a data set is itself a smooth curve. \cite{bugni_permutation_2021} develop a permutation test that tries to answer this question by combining two distinct test statistics. To explore their approach, it is first necessary to introduce some theoretical concepts.
		Section \ref{FDA} introduces the necessary concepts from functional data analysis. Section \ref{CvM_Tests} explores the theory around Cram\'{e}r-von Mises tests. Section \ref{Multiple_Testing} introduces the Bonferroni Correction for multiple testing problems and Section \ref{Permutation_Tests} finally introduces the necessary background in Permutation Testing.\\
		After explaining these concepts, section \ref{Bugni_Horowitz_2021} focuses on the test developed in \cite{bugni_permutation_2021} for the case of a two sample test. Section \ref{Simulation_Study} replicates the results from the simulation study in the paper and section \ref{Application} explores their usefulness in an application to {\color{red} Thema der Anwendung}.
	
	\section{Functional Data Analysis}\label{FDA}
		The overarching concept of functional data analysis is to incorporate observations that are functional in nature. In this context, a functional observation can often be understood as a smooth curve. A classical example of this is shown in Figure \ref{growth_curves}. It presents data provided in the R package \textit{fda}\footcite{fda} and shows growth curves of 93 humans up to the age of 18.
		\begin{figure}[H]
			\includegraphics[width = \textwidth]{../Graphics/growth\_curves.PDF}
			\caption{Human Growth Curves up to the Age of 18}
			\label{growth_curves}
		\end{figure}
		Even though the measurements were taken at discrete ages, it is clear that each human has a height at every point in time. The data points are only measurements of this continuous curve. The higher the measurement frequency, the closer we get to data that resembles the curve itself.
		
		In many cases functional data analysis restricts its scope to subsets of the functions $f:\mathbb{R} \rightarrow \mathbb{R}$.
		As these are inherently infinite-dimensional, it is necessary to introduce additional theory to appropriately deal with their unique properties.
		
		
		\begin{itemize}
			\item \cite{ramsay_functional_2005}
			\item \cite{kokoszka_introduction_2021}
			\item \cite{hsing_theoretical_2015}
		\end{itemize}
	
		\subsection{Hilbert Space of Square Integrable Functions}
			\begin{definition}[Inner Product]
				A function $\langle \cdot , \cdot \rangle : \mathbb{V}^2 \rightarrow \mathbb{R}$ on a vector space $\mathbb{V}$ is called an inner product if the following four conditions hold for all $v, v_1, v_2 \in \mathbb{V}$ and $a_1, a_2 \in \mathbb{R}$.
				\begin{multicols}{2}
					\begin{enumerate}
						\item $\langle v,v \rangle \geq 0$
						\item $\langle v,v \rangle = 0$ if $v = 0$
						\item $\langle a_1 v_1 + a_2 v_2, v \rangle = a_1 \langle v_1, v \rangle + a_2 \langle v_2, v \rangle$
						\item $\langle v_1, v_2 \rangle = \overline{\langle v_2, v_1 \rangle}$
					\end{enumerate}
				\end{multicols}
			\end{definition}
			
			\cite{hsing_theoretical_2015}
			\begin{definition}[Inner Product Space]
				A vector space with an associated inner product is called an inner product space.
			\end{definition}
		
			\cite{hsing_theoretical_2015}
			\begin{definition}[Hilbert Space]
				A complete inner product space is called a Hilbert space.
			\end{definition}
		
			\begin{definition}[Basis of a Hilbert Space]
				content...
			\end{definition}
		
			\begin{definition}[Separable Hilbert Space]
				content...
			\end{definition}
		
			\begin{definition}[Hilbert Space of Square Integrable Functions]
				
				The space of square integrable functions on a closed interval $A$ together with the norm $\langle f,g\rangle = \int_A f(t)g(t) \mathrm{d}t$ is a Hilbert space.
				A function $f: A \rightarrow \mathbb{R}$ is called square integrable if the following condition holds.
				\begin{equation}
					\int_{A} \left[f(t)\right]^2\mathrm{d}t < \infty
				\end{equation}
				The Hilbert space of all square integrable functions on $A$ is denoted by $\mathbb{L}_2(A)$.
			\end{definition}
		
			In most cases, $A$ is chosen as a closed interval of $\mathbb{R}$. So without loss of generality, we can reduce our treatment to the case of $A = [0,1]$.
		
		\subsection{Bases of $\mathbb{L}_2$}
			\begin{itemize}
				\item Orthogonality
				\item Orthonormality
			\end{itemize}
			
			One commonly used orthonormal basis of $\mathbb{L}^2([0,1])$ is the Fourier Basis. It consists of a series of functions $\left(\phi_{i}^{F}(x)\right)_{i \in \mathbb{N}}$ taken from the terms of the sine-cosine form of the Fourier series.
			\begin{equation}
				\phi_{i}^{F}(x) = 
				\begin{cases}
					1 & \text{if} \quad i = 1\\
					\sqrt{2} \cos(\pi i x) & \text{if} \quad i \quad \text{is even} \\
					\sqrt{2} \sin(\pi (i-1)x) & \text{otherwise}
				\end{cases}
			\end{equation}
			Figure \ref{fourier_basis} shows the first seven Fourier basis functions on $[0,1]$.
			\begin{figure}[H]
				\includegraphics[width = \textwidth]{../Graphics/fourier\_basis.PDF}
				\caption{The first seven Fourier basis functions}
				\label{fourier_basis}
			\end{figure}
			A proof that the Fourier basis is in fact an orthonormal basis of $\mathbb{L}^2([0,1])$ can be found in section 2.4 of \cite{hsing_theoretical_2015}.
	
		\subsection{Random Functions}
		
		\subsection{Probability Measures on $\mathbb{L}_2$}
			\begin{itemize}
				\item Kolmogorov Extension Theorem
				\item \cite{gihman_theory_2004}
			\end{itemize}
		
		\subsection{Functional Integration on $\mathbb{L}_2$}
			\begin{itemize}
				\item Perturbation theory
			\end{itemize}
		
			Functional Integral:
			\begin{equation}
				\int_{\mathbb{L}_2(\mathcal{I})} G\left[f\right] \left[Df\right] = \int_{-\infty}^{\infty}\dots\int_{-\infty}^{\infty} G\left[f\right] \prod_{x} \mathrm{d}f(x)
			\end{equation}
		
			If a representation in terms of an orthogonal functional basis is possible:
			\begin{equation}
				\int_{\mathbb{L}_2(\mathcal{I})} G\left[f\right] \left[Df\right] = \int_{-\infty}^{\infty}\dots\int_{-\infty}^{\infty} G\left(f_1, f_2, \dots\right) \prod_{n} \mathrm{d}f_n
			\end{equation}
		
			An in-depth treatment of integration on Hilbert spaces is available in \cite{skorohod_integration_1974}.
		
	\section{Cram\'{e}r-von Mises Tests}\label{CvM_Tests}
		In applied econometrics, it is often interesting to ask whether the same stochastic process generated the observations in two distinct data sets. In an experimental setting, we could ask whether a treatment assigned at random to a subset of agents changed the distribution of an outcome variable. 
		One approach to answering this question is given by the two-sample Cram\'{e}r-von Mises test.
		
		\begin{itemize}
			\item \cite{darling_kolmogorov-smirnov_1957}
			\item \cite{anderson_asymptotic_1952}
			\item \cite{buning_nichtparametrische_2013}
		\end{itemize}
	
		\subsection{Empirical Distribution Functions}
			
			\cite{gibbons_nonparametric_2021}
			\begin{definition}[Order Statistic]
				
				Let $\{x_i \: \vert \: i = 1, \dots , n\}$ be a random sample from a population with continuous cumulative distribution function $F_X$. Then there almost surely exists a unique ordered arrangement within the sample. 
				
				$$X_{(1)} < X_{(2)} < \dots < X_{(n)}$$
				
				$X_{(r)} \quad r \in \{1, \dots, n\}$ is called the $r$th-order statistic.	
			\end{definition}
		
			\begin{definition}[Empirical Distribution Function]
				\begin{equation}
					F_{n}(x) = \begin{cases}
						0 & \quad \text{if} \quad  x < x_{(1)} \\
						\frac{r}{n} & \quad \text{if} \quad  x_{(r)} \leq x < x_{(r + 1)} \\
						1 & \quad \text{if} \quad  x \geq x_{(n)}
					\end{cases}
				\end{equation}
			\end{definition}
		
		\subsection{Nullhypothesis}
			Let $\{x_1, \dots , x_n\}$ and $\{y_1, \dots , y_m\}$ be two data sets generated by random variables $X \sim_{\text{i.i.d.}} F(t)$ and $Y \sim_{\text{i.i.d.}} G(t)$.
			Then, we can formulate the Nullhypothesis that both samples were generated by random variables following the same distribution function.
			\begin{equation}
				\begin{split}
					H_0&: F(t) = G(t) \quad \forall t \in \mathbb{R}\\
					H_1&: \exists t \in \mathbb{R} \quad \text{s.t.} \quad F(t) \neq G(t)
				\end{split}
			\end{equation}
			
		\subsection{Two-Sample Cram\'{e}r-von Mises Statistic}
			
			\cite{buning_nichtparametrische_2013}
			\begin{equation}
				C_{m,n} = \left(\frac{nm}{n+m}\right) \int_{-\infty}^{\infty}\left(F_{m}(x) - G_{n}(x)\right)^{2} \mathrm{d} \left(\frac{m F_{m}(x) + n G_{n}(x)}{m+n}\right)
			\end{equation}
			\cite{anderson_distribution_1962} explores the small sample distribution of this test statistic and provides a comparison to the limiting distribution derived by \cite{rosenblatt_limit_1952} and \cite{fisz_result_1960}.
		
		\subsection{Asymptotic Distributions}
			As shown by the previously mentioned authors, under the Nullhypothesis that both samples were independently generated by random variables sharing the same distribution function, we can find the following limiting distribution of $C_{m,n}$.
			\begin{equation}
				\begin{split}
					C_{m,n} &\xrightarrow{\text{d}} \int_{0}^{1} \left(Z(u) + \left(1 + \lambda\right)^{-\frac{1}{2}} f(u) - \left[\frac{\lambda}{1+\lambda}\right]^{\frac{1}{2}}g(u)\right)^2 \mathrm{d}u \\
					\text{as} \quad &n \rightarrow \infty, \quad m \rightarrow \infty, \quad \frac{n}{m} \rightarrow \lambda \in \mathbb{R}
				\end{split}
			\end{equation}
			Here, $Z(u)$ is a Gaussian stochastic process with the following properties.
			\begin{itemize}
				\item $\mathbb{E}\left[Z(u)\right] = 0 \quad \forall u \in [0,1]$
				\item $Cov\left(Z(u), Z(v)\right) = \min(u,v) - uv \quad \forall u,v \in [0,1]$
			\end{itemize}		
		
	\section{Multiple Testing}\label{Multiple_Testing}
		When testing statistical hypotheses, it is often helpful or even necessary to test multiple hypotheses independently of each other. One setting where this could be useful is when we want to combine the desirable properties of two tests, as is done by \cite{bugni_permutation_2021}. If the tests do not perfectly depend on each other, this creates a problem relating to the size of the combined test.
	
		\subsection{Bonferroni Correction}	
			The most straightforward correction for this multiple testing problem is the so-called Bonferroni Correction. Introduced by \cite{dunn_multiple_1961}, it is based on Boole's Inequality, which is sometimes referred to as the Bonferroni Inequality.
			\begin{equation}
				\mathbb{P}\left[\bigcup_{i = 1}^{\infty} A_i\right] \leq \sum_{i = 1}^{\infty} \mathbb{P}\left[A_i\right]
			\end{equation}
			for a countable set of events $A_1, A_2, \dots$.
		
	\section{Permutation Tests}\label{Permutation_Tests}
		In layman's terms, the idea of a permutation test is the following: if two samples show distinctly different properties, that will lead to differences in an appropriately chosen summary statistic. If we were to permute the elements of the groups randomly, we would expect these differences to disappear.
		Permutation tests formalize this intuition. 
		
		\begin{itemize}
			\item \cite{lehmann_testing_2005}
			\item \cite{van_der_vaart_weak_1996}
		\end{itemize}
	
		\subsection{Functional Principle of Permutation Tests}
			Let $\{x_1, x_2, \dots, x_n\}$ and $\{y_1, y_2, \dots, y_m\}$ be two data sets.
		
			Number of Permutations: $(n+m)!$\\
			Number of Combinations: $\binom{m+n}{m}$\\
			
			For my implementation, I chose the latter variant.
	
		\subsection{Size and Power}
		
	\section{Test by Bugni and Horowitz (2021)}\label{Bugni_Horowitz_2021}
		\begin{itemize}
			\item \cite{bugni_permutation_2021}
			\item \cite{bugni_goodness--fit_2009}
		\end{itemize}
	
		Distribution Functions
		\begin{equation}
			\begin{split}
				F_X(z) &= \mathbb{P}\left[X(t) \leq z(t) \quad \forall t \in \mathcal{I}\right] \quad z \in \mathbb{L}_2(\mathcal{I})\\
				F_Y(z) &= \mathbb{P}\left[Y(t) \leq z(t) \quad \forall t \in \mathcal{I}\right] \quad z \in \mathbb{L}_2(\mathcal{I})
			\end{split}
		\end{equation}
	
		\subsection{Nullhypothesis}
			\begin{equation}
				\begin{split}
					H_0: \quad &F_X(z) = F_Y(z) \quad \forall z \in \mathbb{L}_2(\mathcal{I}) \\
					H_1: \quad &\mathbb{P}_{\mu}\left[F_X(Z) \neq F_Y(Z)\right] > 0
				\end{split}
			\end{equation}
			Here, $\mu$ is a probability measure on $\mathbb{L}_2(\mathcal{I})$ and $Z$ is a random function with probability distribution $\mu$. {\color{red} Doesn't this leave out the case where the Probability functions only differ on a set of $\mu$-measure zero?}
		
		\subsection{Assumptions}
		
			\begin{assumption} Contains two assumptions
				\begin{enumerate}
					\item $X(t)$ and $Y(t)$ are separable, $\mu$-measurable stochastic processes.
					\item $\{X_i(t) \: \vert \: i = 1, \dots, n\}$ is an independent random sample of the process $X(t)$. \\
					$\{Y_i(t) \: \vert \: i = 1, \dots, m\}$ is an independent random sample of $Y(t)$ and is independent of $\{X_i(t) \: \vert \: i = 1, \dots, n\}$.
				\end{enumerate}
			\end{assumption}
		
			\begin{assumption}
				$\mathbb{E}X(t)$ and $\mathbb{E}Y(t)$ exist and are finite for all $t \in [0, T]$.
			\end{assumption}
		
			\begin{assumption}
				$X_i(t)$ and $Y_i(t)$ are observed for all $t \in \mathcal{I}$.
			\end{assumption}
	
		
			
		
		\subsection{Cram\'{e}r-von Mises type Test}
		
			Empirical Distribution Functions
			\begin{multicols}{2}
				\noindent
				\begin{equation*}
					\hat{F}_X(z) = \frac{1}{n} \sum_{i = 1}^{n}\mathbbm{1}\left[X_i(t) \leq z(t) \ \forall t \in \mathcal{I}\right]
				\end{equation*}
				\begin{equation}
					\hat{F}_Y(z) = \frac{1}{m} \sum_{i = 1}^{m}\mathbbm{1}\left[Y_i(t) \leq z(t) \ \forall t \in \mathcal{I}\right]
				\end{equation}
			\end{multicols}
			
			
			Test statistic
			\begin{equation}
				\tau = \int_{\mathbb{L}_2(\mathcal{I})}\left[F_X(z) - F_Y(z)\right]^2 \mathrm{d} \mu(z)
			\end{equation}
			
			Sample analog:
			\begin{equation}
				\tau_{n,m} = (n+m) \int_{\mathbb{L}_2(\mathcal{I})}\left[\hat{F}_X(z) - \hat{F}_Y(z)\right]^2 \mathrm{d} \mu(z)
			\end{equation}
		
			Critical values for Permutation Test Statistic
			\begin{equation}
				t^{*}_{n,m}(1-\alpha) = \inf \left\{t \in \mathbb{R} \quad \vert \quad \frac{1}{Q} \sum_{i = 1}^{Q} \mathbbm{1}\left[\tau_{n,m,q} \leq t\right] \geq 1 - \alpha \right\}
			\end{equation}
		
		\subsection{Mean focused Test}
			
			Test statistic
			\begin{equation}
				\nu = \int_{\mathcal{I}} \left[\mathbb{E}X(t) - \mathbb{E}Y(t)\right]^2 \mathrm{d}t
			\end{equation}
		
			Mean Estimators
			\begin{multicols}{2}
				\noindent
				\begin{equation*}
					\hat{\mathbb{E}}X(t) = \frac{1}{n}\sum_{i = 1}^{n} X_i(t)
				\end{equation*}
				\begin{equation}
					\hat{\mathbb{E}}Y(t) = \frac{1}{m}\sum_{i = 1}^{m} Y_i(t)
				\end{equation}
			\end{multicols}
		
			Sample Analog
			\begin{equation}
				\nu_{n,m} = (n+m) \int_{\mathcal{I}} \left[\hat{\mathbb{E}}X(t) - \hat{\mathbb{E}}Y(t)\right]^2 \mathrm{d}t
			\end{equation}
		
			Critical values for Permutation Test Statistic
			\begin{equation}
				t^{*}_{n,m}(1-\alpha) = \inf \left\{t \in \mathbb{R} \quad \vert \quad \frac{1}{Q} \sum_{i = 1}^{Q} \mathbbm{1}\left[\nu_{n,m,q} \leq t\right] \geq 1 - \alpha \right\}
			\end{equation}
		
		\subsection{Combined Permutation Test}
			Define for the two underlying tests the following objects.
			\begin{multicols}{2}
				\noindent
				\begin{equation*}
					\phi_{n,m} = \begin{cases}
						1 &\text{if} \ \tau_{n,m} > t^{*}_{n,m}(1-\alpha_{\tau}) \\
						a_{\tau} &\text{if} \ \tau_{n,m} = t^{*}_{n,m}(1-\alpha_{\tau}) \\
						0 &\text{if} \ \tau_{n,m} < t^{*}_{n,m}(1-\alpha_{\tau}) \\
					\end{cases}
				\end{equation*}
				\begin{equation}
					\tilde{\phi}_{n,m} = \begin{cases}
						1 &\text{if} \ \nu_{n,m} > t^{*}_{n,m}(1-\alpha_{\nu}) \\
						a_{\nu} &\text{if} \ \nu_{n,m} = t^{*}_{n,m}(1-\alpha_{\nu}) \\
						0 &\text{if} \ \nu_{n,m} < t^{*}_{n,m}(1-\alpha_{\nu}) \\
					\end{cases}
				\end{equation}
			\end{multicols}
			$a_\tau$ and $a_\nu$ are given by the following equations to ensure that the expected values of $\phi$ and $\tilde{\phi}$ have the desired values.
			\begin{multicols}{2}
				\begin{itemize}
					\item $a_{\tau} = \frac{Q\alpha_{\tau} - Q_{\tau}^{+}}{Q_{\tau}^{0}}$ 
					\item $Q_{\tau}^{+} = \sum_{q = 1}^{Q}\mathbbm{1}\left[\tau_{n,m,q} > t^{*}_{n,m}(1-\alpha_{\tau})\right]$
					\item $Q_{\tau}^{0} = \sum_{q = 1}^{Q}\mathbbm{1}\left[\tau_{n,m,q} = t^{*}_{n,m}(1-\alpha_{\tau})\right]$
					\item $a_{\nu} = \frac{Q\alpha_{\nu} - Q_{\nu}^{+}}{Q_{\nu}^{0}}$ 
					\item $Q_{\nu}^{+} = \sum_{q = 1}^{Q}\mathbbm{1}\left[\nu{n,m,q} > t^{*}_{n,m}(1-\alpha_{\nu})\right]$
					\item $Q_{\nu}^{0} = \sum_{q = 1}^{Q}\mathbbm{1}\left[\nu{n,m,q} = t^{*}_{n,m}(1-\alpha_{\nu})\right]$
				\end{itemize} 
			\end{multicols}
			
			Bonferroni inequality under $H_0$ leads to
			\begin{equation}
				\max(\alpha_{\tau}, \alpha_{\nu}) \leq \mathbb{P}\left[(\phi_{n,m} > 0) \cup (\tilde{\phi}_{n,m} > 0)\right] \leq \alpha_{\tau} + \alpha_{\nu}
			\end{equation}
		
		\subsection{Properties}
		
	\section{Simulation Study}\label{Simulation_Study}
		\subsection{Implementation as an R package}
			All analyses in this thesis have been conducted with R\footcite{R}. I implemented the two-sample variant of the test presented taken from \cite{bugni_permutation_2021} in an R package called \textit{PermFDATest}. The R package and all code that has been used to produce the following results are publicly available as part of a GitHub repository\footnote{\href{https://github.com/JakobJuergens/Masters_Thesis}{https://github.com/JakobJuergens/Masters\_Thesis}} that complements this thesis.
			
			\begin{itemize}
				\item \cite{fda}
				\item \cite{tidyverse}
				\item \cite{refund}
			\end{itemize}
			
		\subsection{Use of High-Performance Computing}
			The simulations presented as part of this thesis have been conducted on \textit{bonna}\footnote{\href{https://www.dice.uni-bonn.de/de/hpc/hpc-a-bonn/infrastruktur}{https://www.dice.uni-bonn.de/de/hpc/hpc-a-bonn/infrastruktur}}. \textit{bonna} is the high performance computing cluster provided by the University of Bonn. The implementation is heavily parallelized and makes use of a SLURM scheduling system. However, slight modifications of the provided code suffice to run it on personal computers.

		\subsection{Simulation Setup}
		
		\subsection{Results}
		
	\section{Application}\label{Application}
	
	\section{Outlook}\label{Outlook}
	
	\newpage
	\section{Bibliography}
	\printbibliography[heading=none]
	
	\newpage
	\cleardoublepage
	\pagenumbering{roman}
	\setcounter{page}{1}
	\section{Appendix}
	
	\newpage
	\thispagestyle{empty}
	\section*{Versicherung an Eides statt}	
	
		\vspace{3cm}
		
		Ich versichere hiermit, dass ich die vorstehende Masterarbeit
		selbstst√§ndig verfasst und keine anderen als die angegebenen Quellen
		und Hilfsmittel benutzt habe, dass die vorgelegte Arbeit noch an keiner
		anderen Hochschule zur Pr√ºfung vorgelegt wurde und dass sie weder
		ganz noch in Teilen bereits ver√∂ffentlicht wurde. W√∂rtliche Zitate und
		Stellen, die anderen Werken dem Sinn nach entnommen sind, habe ich
		in jedem einzelnen Fall kenntlich gemacht.
		
		\vspace{2cm}
		Bonn, XX.XX.2021 \hrulefill \\
		\hspace*{0mm}Jakob R. Juergens
		
		\vspace{\fill}
\end{document}